{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12cb397d",
   "metadata": {},
   "source": [
    "<table style=\"border: none; text-align: center\" width=\"100%\">\n",
    "  <tr style=\"border: none\">\n",
    "    <td style=\"min-width:250px; border:none; text-align:left\" bgcolor=\"white\">\n",
    "      <a href=\"https://www.audiolabs-erlangen.de/\" target=\"_blank\">\n",
    "        <img src=\"./files/logo_alabs.svg\" style=\"height:30px; display:inline-block\" />\n",
    "      </a>\n",
    "    </td>\n",
    "    <td style=\"min-width:250px; border:none; text-align:center\" bgcolor=\"white\">\n",
    "      <a href=\"https://www.fau.de/\" target=\"_blank\">\n",
    "        <img src=\"./files/logo_fau.svg\" style=\"height:50px; display:inline-block\" />\n",
    "      </a>\n",
    "    </td>\n",
    "    <td style=\"min-width:250px; border:none; text-align:right\" bgcolor=\"white\">\n",
    "      <a href=\"https://www.iis.fraunhofer.de/\" target=\"_blank\">\n",
    "        <img src=\"./files/logo_iis.svg\" style=\"height:30px; display:inline-block\" />\n",
    "      </a>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<h1>Harmonic Percussive Source Separation</h1>\n",
    "<b>Lab Course</b><br/>\n",
    "<b>International Audio Laboratories Erlangen</b><br/>\n",
    "<b>Prof. Dr. Meinard M체ller</b><br/>\n",
    "<b>Winter Term 2018/19</b>\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div class=\"list-group\">\n",
    "  <a style=\"padding: 7px\" class=\"list-group-item disabled\"><b>Authors</b></a>\n",
    "  <a style=\"padding: 7px\" href=\"https://www.audiolabs-erlangen.de/fau/professor/mueller\" class=\"list-group-item\">Meinard M체ller</a>\n",
    "  <a style=\"padding: 7px\" href=\"https://www.audiolabs-erlangen.de/fau/assistant/driedger\" class=\"list-group-item\">Jonathan Driedger</a>\n",
    "    <a style=\"padding: 7px\" href=\"https://www.audiolabs-erlangen.de/fau/assistant/praetzlich\" class=\"list-group-item\">Thomas Pr채tzlich</a>\n",
    "  <a style=\"padding: 7px\" href=\"https://www.audiolabs-erlangen.de/fau/assistant/zalkow\" class=\"list-group-item\">Frank Zalkow</a>\n",
    "</div>\n",
    "\n",
    "<div class=\"list-group\">\n",
    "  <a style=\"padding: 7px\" class=\"list-group-item disabled\"><b>Tutors of this Semester</b></a>\n",
    "  <a style=\"padding: 7px\" href=\"https://www.audiolabs-erlangen.de/fau/assistant/lopez\" class=\"list-group-item\">Patricio L처pez-Serrano</a>\n",
    "  <a style=\"padding: 7px\" href=\"https://www.audiolabs-erlangen.de/fau/assistant/rosenzweig\" class=\"list-group-item\">Sebastian Rosenzweig</a>\n",
    "  <a style=\"padding: 7px\" href=\"https://www.audiolabs-erlangen.de/fau/assistant/zalkow\" class=\"list-group-item\">Frank Zalkow</a>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<em>Harmonic Percussive Source Separation</em>, &copy; September 2018\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e78ba",
   "metadata": {},
   "source": [
    "## <a name=\"abstract\"></a> Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a2de0d",
   "metadata": {},
   "source": [
    "Sounds can broadly be classified into two classes. Harmonic\n",
    "sound on the one hand side is what we perceive as\n",
    "pitched sound and what makes us hear melodies and chords.\n",
    "Percussive sound on the other hand is noise-like and usually\n",
    "stems from instrument onsets like the hit on a drum or from\n",
    "consonants in speech.\n",
    "The goal of harmonic-percussive\n",
    "source separation (HPSS) is to decompose an input audio signal\n",
    "into a signal consisting of all harmonic sounds\n",
    "and a signal consisting of all percussive sounds.\n",
    "In this lab course, we study an HPSS algorithm and implement it in Python.\n",
    "Exploiting knowledge about the spectral structure of harmonic and percussive sounds,\n",
    "this algorithm decomposes the spectrogram of the given input signal\n",
    "into two spectrograms, one for the harmonic, and one for the percussive component.\n",
    "Afterwards, two waveforms are reconstructed from the spectrograms\n",
    "which finally form the desired signals.\n",
    "Additionally, we describe the application of HPSS for enhancing chroma feature extraction and onset detection.\n",
    "The techniques used in this lab cover median filtering, spectral masking and\n",
    "the inversion of the short-time Fourier transform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4459cb5",
   "metadata": {},
   "source": [
    "## <a name=\"hpss\"></a> Harmonic-Percussive Source Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab76351",
   "metadata": {},
   "source": [
    "When listening to our environment, there exists a wide variety of different sounds.\n",
    "However, on a very coarse level, many sounds can be\n",
    "categorized to belong in either one of two classes:\n",
    "harmonic or percussive sounds.\n",
    "Harmonic sounds are the ones which we perceive to have a certain *pitch* such that we could for example sing along to them.\n",
    "The sound of a violin is a good example of a harmonic sound.\n",
    "*Percussive* sounds often stem from two colliding objects like for example the two shells of castanets.\n",
    "An important characteristic of percussive sounds is that they do not have a pitch but a very clear\n",
    "localization in time.\n",
    "Many real-world sounds are mixtures of harmonic and percussive components.\n",
    "For example, a note played on a piano has a percussive onset (resulting from the hammer hitting the strings)\n",
    "preceding the harmonic tone (resulting from the vibrating string)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b590f26",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Homework Exercise 1</b><br>\n",
    "Think about three real world examples of sounds which are clearly harmonic and three examples of\n",
    "      sounds which are clearly percussive.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a9d8e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "What are characteristics of harmonic and percussive signals? Sketch a\n",
    "      waveform of a percussive signal and the waveform of a harmonic signal. What are the main\n",
    "      differences between those waveforms?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291f25b",
   "metadata": {},
   "source": [
    "The goal of harmonic-percussive source separation (HPSS) is to decompose a given input signal into a\n",
    "sum of two component signals,\n",
    "one consisting of all harmonic sounds and the other consisting of all percussive sounds.\n",
    "The core observation in many HPSS algorithms is that in a spectrogram representation of the\n",
    "input signal, harmonic sounds tend to form horizontal structures (in time-direction), while\n",
    "percussive sounds form vertical structures (in frequency-direction).\n",
    "For an example, have a look at following Figure where you can see the power spectrograms of two signals.\n",
    "The left Figure shows the power spectrogram of a sine-tone with a frequency of\n",
    "$4000$ Hz and a duration of one second.\n",
    "This tone is as harmonic as a sound can be.\n",
    "The power spectrogram shows just one horizontal line.\n",
    "Contrary, the power spectrogram on the rigtht side shows just one vertical line.\n",
    "It is the spectrogram of a signal which is zero everywhere, except for the sample at $0.5$ seconds  where it is one.\n",
    "Therefore, when listening to this signal, we just hear a brief ``click'' at $0.5$ seconds.\n",
    "This signal is the prototype of a percussive sound.\n",
    "The same kind of structures can be observed in lower Figure, which shows a\n",
    "spectrogram of a violin recording and a spectrogram of a castanets recording.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>\n",
    "      <img src=\"./files/figure_spec_sinusoid.svg\">\n",
    "     </th>\n",
    "     <th>\n",
    "      <img src=\"./files/figure_spec_impulse.svg\">\n",
    "     </th>\n",
    "   </tr>\n",
    "   <tr>\n",
    "    <th style=\"text-align: center;\">\n",
    "      Spectrogram of an ideal harmonic signal.\n",
    "     </th>\n",
    "     <th style=\"text-align: center;\">\n",
    "      Spectrogram of an ideal percussive signal.\n",
    "     </th>\n",
    "   </tr>\n",
    "   <tr>\n",
    "    <th>\n",
    "      <img src=\"./files/figure_spec_violin.svg\">\n",
    "     </th>\n",
    "     <th>\n",
    "      <img src=\"./files/figure_spec_castanets.svg\">\n",
    "     </th>\n",
    "   </tr>\n",
    "   <tr>\n",
    "    <th style=\"text-align: center;\">\n",
    "      Spectrogram of a recording of a violin.\n",
    "     </th>\n",
    "     <th style=\"text-align: center;\">\n",
    "      Spectrogram of a recording of a castanets.\n",
    "     </th>\n",
    "   </tr>\n",
    "</table>\n",
    "\n",
    "Real world signals are usually mixtures of harmonic and percussive sounds.\n",
    "Furthermore, there is no absolute definition of when a sound stops \"being harmonic\" and starts \"being percussive\".\n",
    "Think, for example, of white noise which cannot be assigned to either one of these classes.\n",
    "However, with the above observations it is possible to decide if a time-frequency instance\n",
    "of a spectral representation of the input signal, like the short-time Fourier transform (STFT), belongs rather to\n",
    "the harmonic component or rather to the percussive component.\n",
    "This can be done in the following way.\n",
    "Assume we want to find out if a time-frequency bin in the STFT of the input signal belongs\n",
    "to the harmonic component.\n",
    "In this case, the bin should be part of some horizontal, and therefore harmonic structure.\n",
    "We can check this by first applying some filter to the power spectrogram of the STFT, which enhances horizontal structures\n",
    "and suppresses vertical structures and see if the filtered bin has some \"high value\".\n",
    "However, even if its value is high, it might still belong to some even stronger vertical, and therefore\n",
    "percussive structure.\n",
    "We therefore apply another filter to the power spectrogram which enhances vertical structures and suppresses horizontal structures.\n",
    "Now, in the case that the value of our bin in this vertically enhanced spectrogram is lower than in the horizontally enhanced\n",
    "spectrogram, it is very likely that it belongs to some harmonic sound and we can assign it to the harmonic component.\n",
    "Otherwise, if its value was higher in the vertically enhanced spectrogram, we directly know that it is rather\n",
    "part of some percussive sound and assign it to the percussive component.\n",
    "This way, we can decide for every time-frequency instance of the original STFT of the input signal whether it belongs\n",
    "to the harmonic, or to the percussive component and construct two new STFTs.\n",
    "In the STFT for the harmonic component, all bins which were assigned to the percussive component are set to zero,\n",
    "and vice versa for the percussive component.\n",
    "Finally, by \"inverting\" these STFTs, we get the audio signals for the harmonic and the percussive component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d228c1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Homework Exercise 2</b><br>\n",
    "Suppose you apply an HPSS algorithm to white noise. Recall that white noise has a constant power spectral density (it is also said to be flat). What do you expect the harmonic and the percussive\n",
    "      component to sound like?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d5deba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "If you apply an HPSS algorithm to a recording of your favorite rock band. What do you expect\n",
    "      the harmonic and the percussive component to sound like?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb62f4f",
   "metadata": {},
   "source": [
    "## <a name=\"algoritm\"></a> An HPSS Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a95f17",
   "metadata": {},
   "source": [
    "We will now describe an actual HPSS algorithm.\n",
    "Formally, given a discrete input audio signal $x:{\\mathbb Z}\\to{\\mathbb R}$, the algorithm should compute a harmonic component signal $x_\\mathrm{h}$\n",
    "and a percussive component signal $x_\\mathrm{p}$, such that $x = x_\\mathrm{h} + x_\\mathrm{p}$.\n",
    "Furthermore, the signals  $x_\\mathrm{h}$ and $x_\\mathrm{p}$ contain the harmonic and percussive sounds of $x$, respectively.\n",
    "In the following we describe the consecutive steps of an HPSS algorithm.\n",
    "We start with the computation of the *STFT* (Subsection [STFT](#STFT)) and proceed\n",
    "with enhancing the power spectrogram using *median filtering* (Subsection [Median Filtering](#MedFilt)).\n",
    "Afterwards, the filtered spectrograms are used to compute *binary masks* (Subsection [Binary Masking](#Mask)) which are\n",
    "used to construct STFTs for the harmonic and the percussive component.\n",
    "These STFTs are finally transformed back to the time domain (Subsection [ISTFT](#ISTFT))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9647dc",
   "metadata": {},
   "source": [
    "### <a name=\"STFT\"></a> STFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d540967e",
   "metadata": {},
   "source": [
    "In the first step, we compute  the short-time Fourier transform (STFT) ${\\mathcal X}$ of the signal $x$ as:\n",
    "\n",
    "\\begin{equation}\n",
    "    {\\mathcal X}(m,k):= \\sum_{n=0}^{N-1} x(n + m H)w(n)\\exp(-2\\pi ikn/N)\n",
    "\\end{equation}\n",
    "\n",
    "with ${m\\in[0:M-1]:=\\{0,\\ldots,M -1\\}}$ and $k\\in[0:N-1]$, where $M$ is the number of frames,\n",
    "$N$ is the frame size and length of the discrete Fourier transform,\n",
    "${w:[0:N -1]\\to{\\mathbb R}}$ is a window function and $H$ is the hopsize.\n",
    "From ${\\mathcal X}$ we can then derive the power spectrogram ${\\mathcal Y}$ of $x$:\n",
    "\n",
    "\\begin{equation}\n",
    "    {\\mathcal Y}(m,k) := |{\\mathcal X}(m,k)|^2.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608fee72",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Homework Exercise 3</b><br>\n",
    "The parameters of the STFT have a crucial influence on the HPSS algorithm. Think about what happens to ${\\mathcal Y}$ in the case\n",
    "      you choose $N$ to be very large or very small. How could this influence the algorithm? (Hint: Think about how $N$ influences the time- and frequency-resolution of the STFT.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2355950b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Explain in technical terms why harmonic sounds form horizontal and percussive sounds form vertical structures in spectrograms. (Hint: Have a look at the exponential basis functions of the STFT. What does one of these functions describe? How can an impulse be represented with them?)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e67ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Lab Experiment 1</b><br>\n",
    "Load an audio file <samp>CastanetsViolin.wav</samp> using <samp>sf.read</samp>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6259aff1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'soundfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9952e3dd0f98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# your code here...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'files/CastanetViolin.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'soundfile'"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "\n",
    "# your code here...\n",
    "x,Fs=sf.read('files/CastanetViolin.wav')\n",
    "Audio(x, rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c7f09f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Compute the STFT ${\\mathcal X}$ of the input signal $x$ using <samp>librosa.stft</samp> with the parameters <samp>N=1024</samp>, <samp>H=512</samp>, and a hann-window.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09224cdd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4180fde",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Compute the power spectrogram ${\\mathcal Y}$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da00ef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120a5781",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Visualize ${\\mathcal Y}$. Can you spot harmonic and percussive structures?\n",
    "      Apply logarithmic compression with $\\gamma=10$ (see STFT Lab for details on this) when visualizing spectrograms.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410b881",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996469dd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Do the same for the parameters $N=128$, $H=64$, a hann-window, and $N=8192$, $H=4096$, and a hann-window.\n",
    "      How do the spectrograms change when you change the parameters? What happens to the harmonic and percussive structures?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a4cdc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2326e7",
   "metadata": {},
   "source": [
    "### <a name=\"MedFilt\"></a> Median Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7b1f3",
   "metadata": {},
   "source": [
    "In the next step, we want to compute a *harmonically enhanced* spectrogram $\\tilde{{\\mathcal Y}}_\\mathrm{h}$ and\n",
    "a percussively enhanced spectrogram $\\tilde{{\\mathcal Y}}_\\mathrm{p}$ by filtering ${\\mathcal Y}$.\n",
    "This can be done by using a *median filter*.\n",
    "The median of a list of numbers can be found by arranging all numbers from lowest to highest value and picking\n",
    "the middle one.\n",
    "E.g. the median of the list $(7, 3, 4, 6, 5)$ is $5$.\n",
    "Formally, let $A = (a_1, a_2, \\dots, a_L)$ be a list of length $L \\in {\\mathbb N}$ consisting of real numbers $a_l \\in {\\mathbb R}, l \\in [1:L]$.\n",
    "First, the elements of $A$ are sorted in ascending order. This results in a list\n",
    "$\\tilde{A} = (\\tilde{a}_1, \\tilde{a}_2, \\dots, \\tilde{a}_L)$\n",
    "with $\\tilde{a}_l \\leq \\tilde{a}_m$ for $l < m$ and $l, m \\in [1:L]$.\n",
    "Then, the ${\\mathrm{median}}$ of $A$ is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "{\\mathrm{median}}(A) := \\begin{cases} \\tilde{a}_{(L+1)/2} & \\mbox{for $L$ being odd}\\\\ (\\tilde{a}_{L/2} + \\tilde{a}_{L/2+1})/2 & \\mbox{otherwise}\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Now, given a matrix $B\\in{\\mathbb R}^{M\\times K}$, we define harmonic and percussive median filters\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    {\\mathrm{medfilt}_\\mathrm{h}}(B)(m,k) := {\\mathrm{median}}(\\{B(m-\\ell_\\mathrm{h},k),\\ldots,B(m+\\ell_\\mathrm{h},k)\\})\\\\\n",
    "    {\\mathrm{medfilt}_\\mathrm{p}}(B)(m,k) := {\\mathrm{median}}(\\{B(m,k-\\ell_\\mathrm{p}),\\ldots,B(m,k+\\ell_\\mathrm{p})\\})\n",
    "\\end{eqnarray}\n",
    "\n",
    "for $M,K,\\ell_\\mathrm{h},\\ell_\\mathrm{p}\\in{\\mathbb N}$, where $2\\ell_\\mathrm{h} + 1$ and $2\\ell_\\mathrm{p} + 1$ are the lengths of the median filters, respectively.\n",
    "Note that we simply assume $B(m,k)=0$ for $m \\notin [0:M-1]$ or $k \\notin [0:K-1]$.\n",
    "The enhanced spectrograms are then computed as\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    \\tilde{{\\mathcal Y}}_\\mathrm{h} := {\\mathrm{medfilt}_\\mathrm{h}}({\\mathcal Y})\\\\\n",
    "    \\tilde{{\\mathcal Y}}_\\mathrm{p} := {\\mathrm{medfilt}_\\mathrm{p}}({\\mathcal Y})\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0b5446",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Homework Excercise 4</b><br>\n",
    "The arithmetic ${\\mathrm{mean}}$ of a set $A\\subset{\\mathbb R}$ of size $N$ is defined as ${{\\mathrm{mean}}(A):= \\frac{1}{N}\\sum_{n=0}^{N-1}a_n}$.\n",
    "      Compute the ${\\mathrm{median}}$ and the ${\\mathrm{mean}}$ for the set ${A=\\{2, 3, 190, 2, 3\\}}$.\n",
    "      Why do you think the HPSS algorithm employs median filtering and not mean filtering?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b99831b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Apply a horizontal and a vertical median filter of length $3$ to the matrix\n",
    "\n",
    "\\begin{equation*}\n",
    "B =\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 46 & 2 \\\\\n",
    "3 & 1 & 50 & 1 \\\\\n",
    "60 & 68 & 70 & 67 \\\\\n",
    "2 & 1 & 65 & 1\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e69f33",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "# your code here...\n",
    "\n",
    "B = np.array([[1, 1, 46, 2], [3, 1, 50, 1], [60, 68, 70, 67], [2, 1, 65, 1]], dtype='float64')\n",
    "print('Original B:')\n",
    "print(B)\n",
    "print('Horizontally filtered B:')\n",
    "print(horizontal_median_filter(B, 3))\n",
    "print('Vertically filtered B:')\n",
    "print(vertical_median_filter(B, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9921d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Explain in your own words why median filtering allows for enhancing/suppressing harmonic/percussive structures in a spectrogram.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c8b85",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Lab Experiment 2</b><br>\n",
    "Apply harmonic and percussive median filters to the power spectrogram ${\\mathcal Y}$ which you computed in the previous exercise (<samp>N=1024</samp>, <samp>H=512</samp>, and a hann-window using <samp>scipy.signal.medfilt</samp>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c8f133",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75f228",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Play around with different filter lengths (3, 11, 51, 101). Visualize the filtered spectrograms. What are your observations?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a17c68",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e3cb0",
   "metadata": {},
   "source": [
    "### <a name=\"Mask\"></a>  Binary Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd2ae4",
   "metadata": {},
   "source": [
    "Having the enhanced spectrograms $\\tilde{{\\mathcal Y}}_\\mathrm{h}$ and $\\tilde{{\\mathcal Y}}_\\mathrm{p}$, we now need to assign all\n",
    "time-frequency bins of ${\\mathcal X}$ to either the harmonic or the percussive component.\n",
    "This can be done by *binary masking*.\n",
    "A binary mask is a matrix ${\\mathcal M}\\in\\{0,1\\}^{M\\times K}$.\n",
    "It can be applied to an STFT ${\\mathcal X}$ by computing\n",
    "${\\mathcal X} \\odot {\\mathcal M}$, where the operator $\\odot$ denotes point-wise multiplication.\n",
    "A mask value of one preserves the value in the STFT and a mask value of zero suppresses it.\n",
    "For our HPSS algorithm, the binary masks are defined by comparing the values in the enhanced\n",
    "spectrograms $\\tilde{{\\mathcal Y}}_\\mathrm{h}$ and $\\tilde{{\\mathcal Y}}_\\mathrm{p}$.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "{\\mathcal M}_\\mathrm{h}(m,k) :=\n",
    "\\begin{cases}\n",
    "   1 & \\text{if } \\tilde{{\\mathcal Y}}_\\mathrm{h}(m,k) \\geq \\tilde{{\\mathcal Y}}_\\mathrm{p}(m,k) \\\\\n",
    "   0       & \\text{else}\n",
    "  \\end{cases} \\\\\n",
    "{\\mathcal M}_\\mathrm{p}(m,k) :=\n",
    "\\begin{cases}\n",
    "   1 & \\text{if } \\tilde{{\\mathcal Y}}_\\mathrm{p}(m,k) > \\tilde{{\\mathcal Y}}_\\mathrm{h}(m,k) \\\\\n",
    "   0       & \\text{else.}\n",
    "  \\end{cases}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Applying these masks to the original STFT ${\\mathcal X}$ yields the STFTs for the harmonic and the percussive component of the signal\n",
    "${{\\mathcal X}_\\mathrm{h} := ({\\mathcal X} \\odot {\\mathcal M}_\\mathrm{h})}$ and ${{\\mathcal X}_\\mathrm{p} := ({\\mathcal X} \\odot {\\mathcal M}_\\mathrm{p})}$.\n",
    "Note that by the definition of ${\\mathcal M}_\\mathrm{h}$ and ${\\mathcal M}_\\mathrm{p}$, it holds that ${\\mathcal M}_\\mathrm{h}(m,k)+{\\mathcal M}_\\mathrm{p}(m,k) = 1$\n",
    "for $m \\in[0:M-1]$, $k\\in[0:K-1]$.\n",
    "Therefore, every time-frequency bin of ${\\mathcal X}$ is assigned either to ${\\mathcal X}_\\mathrm{h}$ or ${\\mathcal X}_\\mathrm{p}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656a8ff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Homework Excercise 5</b><br>\n",
    "Assume you have the two enhanced spectrograms\n",
    "\n",
    "  \\begin{equation*}\n",
    "  \\begin{array}{cc}\n",
    "      \\tilde{{\\mathcal Y}}_\\mathrm{h} =\n",
    "      \\begin{bmatrix}\n",
    "      1 & 1 & 2 & 2 \\\\\n",
    "      1 & 3 & 1 & 1 \\\\\n",
    "      60 & 68 & 68 & 67 \\\\\n",
    "      1 & 2 & 1 & 1\n",
    "      \\end{bmatrix}, &\n",
    "      \\tilde{{\\mathcal Y}}_\\mathrm{p} =\n",
    "      \\begin{bmatrix}\n",
    "      1 & 1 & 46 & 1 \\\\\n",
    "      3 & 1 & 50 & 2 \\\\\n",
    "      2 & 1 & 65 & 1 \\\\\n",
    "      2 & 1 & 65 & 1\n",
    "      \\end{bmatrix}\n",
    "  \\end{array}\n",
    "  \\end{equation*}\n",
    "\n",
    "Compute the binary masks ${\\mathcal M}_\\mathrm{h}$ and ${\\mathcal M}_\\mathrm{p}$ and apply them to the matrix\n",
    "      \\begin{equation*}\n",
    "      {\\mathcal X} =\n",
    "      \\begin{bmatrix}\n",
    "      1 & 1 & 46 & 2 \\\\\n",
    "      3 & 1 & 50 & 1 \\\\\n",
    "      60 & 68 & 70 & 67 \\\\\n",
    "      2 & 1 & 65 & 1\n",
    "      \\end{bmatrix}\n",
    "      \\end{equation*}\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd32d39",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_h_toy = np.array([[1 ,1, 2, 2], [1, 3, 1, 1], [60, 68, 68, 67], [1, 2, 1, 1]])\n",
    "Y_p_toy = np.array([[1, 1, 46, 1], [3, 1, 50, 2], [2, 1, 65, 1], [2, 1, 65, 1]])\n",
    "X_toy = np.array([[1, 1, 46, 2], [3, 1, 50, 1], [60, 68, 70, 67], [2, 1, 65, 1]])\n",
    "\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ea932",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Lab Experiment 3</b><br>\n",
    "Use the median filtered power spectrograms $\\tilde{{\\mathcal Y}}_\\mathrm{h}$ and $\\tilde{{\\mathcal Y}}_\\mathrm{p}$ from the previous exercise (filter length 11) to compute the binary masks ${\\mathcal M}_\\mathrm{h}$ and ${\\mathcal M}_\\mathrm{p}$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc8b4a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ef388",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Visualize the masks (this time without logarithmic compression).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a492965",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e66f9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Apply the masks to the original STFT ${\\mathcal X}$ to compute ${\\mathcal X}_\\mathrm{h}$ and ${\\mathcal X}_\\mathrm{p}$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840a2c2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caedc0b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Visualize the power spectrograms ${\\mathcal Y}_\\mathrm{h}$ and ${\\mathcal Y}_\\mathrm{p}$ of ${\\mathcal X}_\\mathrm{h}$ and ${\\mathcal X}_\\mathrm{p}$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e455da3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c83454",
   "metadata": {},
   "source": [
    "### <a name=\"ISTFT\"></a>  Inversion of the Short-Time Fourier Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7210b5d5",
   "metadata": {},
   "source": [
    "In the final step, we need to transform our constructed STFTs ${\\mathcal X}_\\mathrm{h}$ and ${\\mathcal X}_\\mathrm{p}$ back to the time-domain.\n",
    "To this end, we apply an \"inverse\" STFT to these matrices to compute the component signals $x_\\mathrm{h}$ and $x_\\mathrm{p}$.\n",
    "Note that the topic \"inversion of the STFT\" is not as trivial as it might seem at the first glance.\n",
    "In the case that ${\\mathcal X}$ is the original STFT of an audio signal $x$, and further preconditions are satisfied (for example that $N \\geq H$ for $N$ being the size of the discrete Fourier transform and $H$ being the hopsize of the STFT),\n",
    "it is possible to invert the STFT and to reconstruct $x$ from ${\\mathcal X}$ perfectly.\n",
    "However, as soon as the original STFT ${\\mathcal X}$ has been modified to some $\\tilde{{\\mathcal X}}$, for example by masking, there might be no audio signal which has exactly $\\tilde{{\\mathcal X}}$ as its STFT.\n",
    "In such a case, one usually aims to find an audio signal whose STFT is \"approximately\" $\\tilde{{\\mathcal X}}$.\n",
    "For this Lab Course, you can simply assume that you can invert the STFT using <samp>librosa.istft</samp>.\n",
    "\n",
    "<img src=\"./files/HPSep3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d43a0d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Homework Excercise 6</b><br>\n",
    "Assume ${\\mathcal X}$ is the original STFT of some audio signal $x$. Why do we need the precondition $N \\geq H$ for $N$ being the size of the discrete Fourier transform and $H$ being the hopsize of the STFT to reconstruct $x$ from ${\\mathcal X}$ perfectly?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eac4b4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Lab Experiment 4</b><br>\n",
    "Apply the inverse STFT function <samp>librosa.istft</samp> to $X_\\mathrm{h}$ and $X_\\mathrm{p}$ from the previous experiment and listen to the results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fa186",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# your code here...\n",
    "\n",
    "display(Audio(x_h, rate=Fs))\n",
    "display(Audio(x_p, rate=Fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f5521",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Save the computed harmonic and percussive component by using <samp>sf.write</samp>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b9beca",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# your code here...\n",
    "\n",
    "display(FileLink('x_h.wav'))\n",
    "display(FileLink('x_p.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3008cfe",
   "metadata": {},
   "source": [
    "### <a name=\"intepret\"></a>  Physical Interpretation of Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacec45a",
   "metadata": {},
   "source": [
    "Note that one can specify the filter lengths of the harmonic and percussive median filters  in seconds and Hertz, respectively.\n",
    "This  makes their physical interpretation easier.\n",
    "Given the sampling rate $F_\\mathrm{s}$ of the input signal $x$ as well as the frame length $N$ and the hopsize $H$,\n",
    "we can convert filter lengths given in seconds and Hertz to filter lengths given in indices\n",
    "\n",
    "\\begin{eqnarray}\n",
    "L_\\mathrm{h}(t):=\\left\\lceil \\frac{F_\\mathrm{s}}{H} t \\right\\rceil\\label{eqn:L_h}\\\\\n",
    "L_\\mathrm{p}(d):=\\left\\lceil \\frac{N}{F_\\mathrm{s}} d \\right\\rceil\\label{eqn:L_p}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ce2e4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Homework Excercise 7</b><br>\n",
    "Assume $F_\\mathrm{s}=22050$ Hz, $N=1024$, and $H=256$. Compute $L_\\mathrm{h}(0.5\\text{ sec})$ and $L_\\mathrm{p}(600 \\text{ Hz})$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c435c0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6506d127",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Lab Experiment 5</b><br>\n",
    "Complete the implementation of the HPSS algorithm in the function <samp>HPSS</samp>:\n",
    "\n",
    "<ol>\n",
    "<li> Compute the STFT ${\\mathcal X}$ of the input signal $x$ using <samp>librosa.stft </samp>.</li>\n",
    "<li> Compute the power spectrogram ${\\mathcal Y}$ from the ${\\mathcal X}$.</li>\n",
    "<li> Convert the median filter lengths from seconds and Hertz to indices. if a filter length is even, subtract 1.</li>\n",
    "<li> Apply median filters to ${\\mathcal Y}$ using <samp>scipy.signal.medfilt</samp> to compute ${\\mathcal Y}_\\mathrm{h}$ and ${\\mathcal Y}_\\mathrm{p}$.</li>\n",
    "<li> Derive the masks ${\\mathcal M}_\\mathrm{h}$ and ${\\mathcal M}_\\mathrm{p}$ from ${\\mathcal Y}_\\mathrm{h}$ and ${\\mathcal Y}_\\mathrm{p}$.</li>\n",
    "<li> Compute ${\\mathcal X}_\\mathrm{h}$ and ${\\mathcal X}_\\mathrm{p}$.</li>\n",
    "<li> Apply the inverse STFT (<samp>librosa.istft </samp>) to get $x_\\mathrm{h}$ and $x_\\mathrm{p}$.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7840162a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def HPSS(x, N, H, w, Fs, lh_sec, lp_Hz):\n",
    "    # x:      Input signal\n",
    "    # N:      Frame length\n",
    "    # H:      Hopsize\n",
    "    # w:      Window function of length N\n",
    "    # Fs:     Sampling rate of x\n",
    "    # lh_sec: Horizontal median filter length given in seconds\n",
    "    # lp_Hz:  Percussive median filter length given in Hertz\n",
    "\n",
    "    # stft\n",
    "\n",
    "    # power spectrogram\n",
    "\n",
    "    # median filtering\n",
    "\n",
    "    # masking\n",
    "\n",
    "    # istft\n",
    "\n",
    "    return x_h, x_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dbbc47",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Test your implementation:\n",
    "\n",
    "<ol>\n",
    "<li> Load the audio files <samp>Stepdad.wav</samp>, <samp>Applause.wav</samp>, and <samp>DrumSolo.wav</samp> from the <samp>Data</samp> folder.</li>\n",
    "<li> Apply HPSS using the parameters <samp>N=1024</samp>, <samp>H=512</samp>, a hann-window, <samp>lh_sec=0.2</samp>, and <samp>lp_Hz=500</samp> to all loaded signals.</li>\n",
    "<li>Listen to the results.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd18078e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for file in ('files/Stepdad.wav', 'files/Applause.wav', 'files/DrumSolo.wav'):\n",
    "    print('# ' + file)\n",
    "\n",
    "    # your code here...\n",
    "\n",
    "    print('Orignal')\n",
    "    display(Audio(x, rate=Fs))\n",
    "    print('Harmonic Component')\n",
    "    display(Audio(x_h, rate=Fs))\n",
    "    print('Percussive Component')\n",
    "    display(Audio(x_p, rate=Fs))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fecbdac",
   "metadata": {},
   "source": [
    "## <a name=\"application\"></a> Applications of HPSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10736dce",
   "metadata": {},
   "source": [
    "In many audio processing tasks, the essential information lies in either the harmonic or the percussive component of an audio signal.\n",
    "In such cases, HPSS is very well suited as a pre-processing step to enhance the outcome of an algorithm.\n",
    "In the following, we introduce two procedures that can be improved by applying HPSS.\n",
    "The harmonic component from the HPSS algorithm can be used to enhance chroma features (Subsection [Chroma](#chroma)) and the  percussive component helps to improve the results of an onset detection procedure (Subsection [Onset](#onset))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7354f6e",
   "metadata": {},
   "source": [
    "## <a name=\"chroma\"></a> Enhancing Chroma Features using HPSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f4f22",
   "metadata": {},
   "source": [
    "Two pitches sound similar when they are an octave apart from each other (12 tones in the equal tempered scale).\n",
    "We say that these pitches share the same chroma which we refer to by the pitch spelling names $\\{\\mathrm{C},\\mathrm{C}^{\\sharp},\\mathrm{D},\\mathrm{D}^{\\sharp},\\mathrm{E},\\mathrm{F},\\mathrm{F}^{\\sharp},\\mathrm{G},\\mathrm{G}^{\\sharp},\\mathrm{A},\\mathrm{A}^{\\sharp},\\mathrm{B}\\}$.\n",
    "Chroma features exploit the above observation, by adding up all frequency bands in a power spectrogram that belong to the same chroma.\n",
    "Technically this can be realized by the following procedure.\n",
    "First we assign a pitch index (MIDI pitch number) to each frequency index $k \\in [1:N/2-1]$ of the spectrogram by using the formula:\n",
    "\n",
    "\\begin{equation}\n",
    "    p(k) =  \\text{round}\\left(12\\log_2\\left( \\frac{ k\\cdot F_\\mathrm{s}}{440 \\cdot N}\\right)\\right)+69.\n",
    "\\end{equation}\n",
    "\n",
    "where $N$ is the number of frequency bins in the spectrogram and $F_\\mathrm{s}$ is the sampling rate of the audio signal.\n",
    "Note that $p$ maps frequency indices corresponding to frequencies around the chamber tone A4 (440 Hz) to its MIDI pitch number 69.\n",
    "Then we add up all frequency bands in the power spectrogram belonging to the same chroma $c \\in [0:11]$:\n",
    "\n",
    "\\begin{equation}\n",
    "      {\\mathcal C}(m,c) := \\sum_ {\\{k |\\,p(k)\\,\\mathrm{mod}\\,12 = c\\,\\}}{{\\mathcal Y}(m,k)}\n",
    "\\end{equation}\n",
    "\n",
    "where $m\\in [0:M-1]$ and $M$ is the number of frames.\n",
    "\n",
    "Chroma features are correlated with the pitches and the harmonic structure of music.\n",
    "Pitches usually form horizontal structures in the spectrogram, whereas transient or percussive sounds form vertical structures. Percussive sounds have a negative impact on the chroma extraction, as they \"activate all frequencies\" in the spectrogram.\n",
    "Hence, one way to improve the chroma extraction is to first apply HPSS and to perform the chroma extraction on the power spectrogram of the harmonic component signal ${\\mathcal Y}_\\mathrm{h}(m,k) = |{\\mathcal X_\\mathrm{h}(m,k)}|^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d6485f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Lab Experiment 6</b><br>\n",
    "Apply the HPSS algorithm as a pre-processing step in a chroma extraction procedure:\n",
    "\n",
    "<ol>\n",
    "<li> Load the file <samp>CastanetsViolin.wav</samp>.</li>\n",
    "<li> Compute chroma features on $x$ with the parameters <samp>N=4410</samp> and <samp>H=2205</samp>.</li>\n",
    "<li> Visualize the chroma features.</li>\n",
    "<li> Apply your HPSS algorithm to separate the castanets from the violin.</li>\n",
    "<li> Use the harmonically enhanced signal $x_\\mathrm{h}$ to compute chroma features and visualize them.</li>\n",
    "<li> Now compare the visualization of the chroma extracted from the original signal $x$ and the chroma extracted from the harmonic component signal $x_\\mathrm{h}$. What do you observe?</li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0634f16b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def simple_chroma(x, N, H, Fs):\n",
    "    # x:       input signal\n",
    "    # N:       frame length\n",
    "    # H:       hopsize\n",
    "    # Fs:      sampling rate\n",
    "\n",
    "    X = librosa.stft(x, N, H, N, window='hann', pad_mode='constant')\n",
    "    Y = np.abs(X) ** 2\n",
    "    Y_comp = np.log(1 + 0.5 * Y)\n",
    "    C = np.zeros((12, Y.shape[1]), dtype=Y.dtype)\n",
    "    n = np.arange(1, Y.shape[0])\n",
    "    pitches = np.round(12 * np.log2((Fs * n/N) / 440)) + 69\n",
    "    chroma_mapping = pitches % 12\n",
    "    chroma_mapping = np.insert(chroma_mapping, 0, -1) # never use DC offset\n",
    "    for k in range(12):\n",
    "        C[k, :] = Y_comp[chroma_mapping == k, :].sum(axis=0)\n",
    "    C = normalize_chroma(C, 2, 0.0001)\n",
    "\n",
    "    return C\n",
    "\n",
    "def normalize_chroma(C, norm_p, threshold):\n",
    "    f_norm = norm(C, norm_p, axis=0)\n",
    "    C_norm = C.copy()\n",
    "    C_norm[:, f_norm >= threshold] /= f_norm\n",
    "    return C_norm\n",
    "\n",
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ede5aa",
   "metadata": {},
   "source": [
    "## <a name=\"onset\"></a> HPSS for Onset Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf0259",
   "metadata": {},
   "source": [
    "Onset detection is the task of finding the temporal positions of note onsets in a music recording.\n",
    "More concrete, the task could be to detect all time positions on which some drum is hit\n",
    "in a recording of a rock song.\n",
    "One way to approach this problem is to assume, that drum hits emit a short burst of high energy\n",
    "and the goal is therefore to detect these bursts in the input signal.\n",
    "To this end, one first computes the *short-time power* ${\\mathcal P}$ of the input signal $x$ by\n",
    "\n",
    "\\begin{equation}\n",
    "    {\\mathcal P}(m):= \\sum_{n=0}^{N-1} x(n + m H)^2 \\quad\n",
    "\\end{equation}\n",
    "\n",
    "where $H$ is the hopsize and $N$ is the length of one frame (similar to the computation of the STFT).\n",
    "Since we are looking for time-positions of high energy, the goal is therefore to detect peaks in ${\\mathcal P}$.\n",
    "A common technique to enhance peaks in a sequence is to\n",
    "subtract the *local average* $\\tilde{{\\mathcal P}}$ from ${\\mathcal P}$ itself. $\\tilde{{\\mathcal P}}$ is defined by\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{{\\mathcal P}}(m) := \\sum_{j=-J}^{J}{\\mathcal P}(m+j) \\frac{1}{2J+1}\n",
    "\\end{equation}\n",
    "\n",
    "for a neighborhood $J\\in{\\mathbb N}$, $m\\in[0:M-1]$, and $M$ is the number of frames.\n",
    "Note that we assume ${\\mathcal P}(m) = 0$ for $m\\notin [0:M-1]$.\n",
    "From this, we compute a *novelty curve* ${\\mathcal N}$\n",
    "\n",
    "\\begin{equation}\n",
    "{\\mathcal N}(m) := \\max(0,{\\mathcal P}(m) - \\tilde{{\\mathcal P}}(m))\n",
    "\\end{equation}\n",
    "\n",
    "The peaks in ${\\mathcal N}$ indicate positions of high energy in $x$, and are therefore potential time positions of drum hits.\n",
    "\n",
    "This procedure works well in case the initial assumption, namely that onsets or drum hits emit some\n",
    "burst of energy which stand out from the remaining energy in the signal, is met.\n",
    "However, especially in professionally mixed music recordings, the short-time energy is often adjusted\n",
    "to be more or less constant over time (compression).\n",
    "One possibility to circumvent this problem is to apply HPSS to the input signal prior to the onset detection.\n",
    "The onset detection is then executed solely on the percussive component which usually contains\n",
    "all drum hits and satisfies the assumption of having energy bursts at the respective time-positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e05f2a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Lab Experiment 7</b><br>\n",
    "Complete the implementation of the onset detection algorithm in the function <samp>onset_detection</samp>:\n",
    "\n",
    "<ol>\n",
    "<li> Compute the short-time power ${\\mathcal P}$ of the input signal $x$ using the provided function <samp>stp</samp>.</li>\n",
    "<li> Compute the local average $\\tilde{{\\mathcal P}}$.\n",
    "              (Hint: Note that the equation can be formulated as a convolution and that you can compute convolutions in Python using the function <samp>np.convolve</samp>.\n",
    "              Note further that this command has an keyword <samp>mode</samp>. Finally, have a look at the function <samp>np.ones</samp>.)</li>\n",
    "<li> Compute the novelty curve ${\\mathcal N}$.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5885c1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stp(x, N, H):\n",
    "    # x:  Input signal\n",
    "    # N:  Frame length\n",
    "    # H:  Hopsize\n",
    "    x_pad = np.concatenate((x, np.zeros(N)))\n",
    "    num_windows = np.ceil(1 + (len(x) - N) / H)\n",
    "    win_pos = np.arange(num_windows) * H\n",
    "    idx = np.array([np.arange(w, w+N) for w in win_pos], dtype='int32')\n",
    "    P = (x_pad[idx] ** 2).sum(axis=1) / N\n",
    "    return P\n",
    "\n",
    "def onset_detection(x, N, H, J):\n",
    "    # x:      Input signal\n",
    "    # N:      Frame length\n",
    "    # H:      Hopsize\n",
    "    # J:      Neighborhood\n",
    "\n",
    "    # short-time power\n",
    "\n",
    "    # local average\n",
    "\n",
    "    # novelty\n",
    "\n",
    "    return N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2504bb21",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Test your implementation by applying it to the audio file <samp>StillPluto_BitterPill.wav</samp>. As a starting point, use $N=882$, $H = 441$, and $J = 10$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b8d5c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here...\n",
    "\n",
    "plt.figure(figsize=(16, 10.66))\n",
    "plt.plot(t, novelty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2bb4b8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Sonify your results using the function <samp>sonify_noveltyCurve</samp>. This function will generate a stereo audio signal in which you can hear the provided original signal\n",
    "      in one of the channels. In the other channel, each peak in the provided novelty curve is audible as a click sound. You can therefore check by listening whether the peaks in your\n",
    "      computed novelty curve are aligned with drum hits in the original signal. To apply the function <samp>sonify_noveltyCurve</samp>, you need to specify the sampling frequency of the\n",
    "      novelty curve. How can you compute it? (Hint: It is dependent on $H$ and the sampling frequency $F_\\mathrm{s}$ of the input audio signal).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114197f4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sonify_noveltyCurve(novelty, x, Fs, sampling_frequency_novelty):\n",
    "    pos = np.append(novelty, novelty[-1]) > np.insert(novelty, 0, novelty[0])\n",
    "    neg = np.logical_not(pos)\n",
    "    peaks = np.where(np.logical_and(pos[:-1], neg[1:]))[0]\n",
    "\n",
    "    values = novelty[peaks]\n",
    "    values /= np.max(values)\n",
    "    peaks = peaks[values >= 0.01]\n",
    "    values = values[values >= 0.01]\n",
    "    peaks_idx = np.int32(np.round(peaks / sampling_frequency_novelty * Fs))\n",
    "\n",
    "    sine_periods = 8\n",
    "    sine_freq = 880\n",
    "    click = np.sin(np.linspace(0, sine_periods * 2 * np.pi, sine_periods * Fs//sine_freq))\n",
    "    ramp = np.linspace(1, 1/len(click), len(click)) ** 2\n",
    "    click = click * ramp\n",
    "    click = (click * np.abs(np.max(x)))\n",
    "\n",
    "    out = np.zeros(len(x), dtype=x.dtype)\n",
    "    for i, start in enumerate(peaks_idx):\n",
    "        idx = np.arange(start, start+len(click))\n",
    "        out[idx] += (click * values[i]).astype(x.dtype)\n",
    "\n",
    "    return np.vstack((x, out))\n",
    "\n",
    "# your code here...\n",
    "\n",
    "Audio(newx, rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639f438",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Listen to the generated results. What is your impression?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12953b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Now apply your HPSS algorithm to the audio file and rerun the detection algorithm on just the percussive component $x_\\mathrm{p}$. Again, sonify the results. What is your impression now?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04697cd2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here...\n",
    "\n",
    "plt.figure(figsize=(16, 10.66))\n",
    "plt.plot(t, novelty)\n",
    "\n",
    "newx = sonify_noveltyCurve(novelty, x, Fs, Fs/H)\n",
    "Audio(newx, rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b1de0b",
   "metadata": {},
   "source": [
    "<h4>Reference</h4>\n",
    "<br/>\n",
    "\n",
    "<div>\n",
    "  <a href=\"http://www.springer.com/gp/book/9783319219448\">\n",
    "    <img src=\"./files/FMP_Cover.png\" alt=\"FMP_Cover\" width=\"80\"  style=\"float:right;\">\n",
    "  </a>\n",
    "</div>\n",
    "\n",
    "<div style=\"float:left;\">\n",
    "<a href=\"https://www.audiolabs-erlangen.de/fau/professor/mueller\">Meinard M체ller</a> <br />\n",
    "Fundamentals of Music Processing &ndash; Audio, Analysis, Algorithms, Applications  <br />\n",
    "ISBN: 978-3-319-21944-8<br />\n",
    "483 p., <a href=\"http://www.springer.com/gp/book/9783319219448\">Springer</a>, 2015  <br />\n",
    "<a href=\"http://www.music-processing.de\">www.music-processing.de</a>    <br />\n",
    "<a href=\"https://www.audiolabs-erlangen.de/fau/professor/mueller/bookFMP\">Accompanying Website</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792bd98b",
   "metadata": {},
   "source": [
    "<h4>Acknowledgment</h4>\n",
    "<br/>\n",
    "The International Audio Laboratories Erlangen are a joint institution of the Friedrich-Alexander-Universit채t Erlangen-N체rnberg (FAU) and Fraunhofer Institute for Integrated Circuits IIS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
